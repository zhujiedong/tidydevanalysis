[
["index.html", "使用 tidyverse 的方式分析仪器测量的数据 欢迎", " 使用 tidyverse 的方式分析仪器测量的数据 祝介东 北京力高泰科技有限公司 2019-03-14 欢迎 Note: 本文内容仅为我 github 中相关 repo (tidydevanalysis) 的在线预览版本，并不保证及时更新。 本文同样纯属个人打发出差漫漫长夜的作品，并非正式资料，只不过尽量使用了 tidyverse 的方式进行，具体成书原因可参考 photoanalysis。 本文能保证的是只要 github 不关，内容就永远可以在线预览，尽量更新，及时纠错。其余事情概不承诺，参考需谨慎。 另，图片仅仅为使得内容显得正式，为网络盗图，侵删。如果你同样在某些时刻闲的无聊，欢迎给我设计个封面。 "],
["frontmatter.html", "前言", " 前言 目的与用途同 photoanalysis，纯属个人项目，在业余爱好者里面很流行的一个词概括为 “just for fun”，当然能帮助到别人也是一件很开心的事情。 关于问题或建议，如果您有 github 帐号，优先欢迎在 github 提交： github地址 此为个人项目，因此问题或建议请反馈至个人邮箱： zhujiedong@yeah.net 如有其他仪器问题或者仪器购买需求，请使用下面方式与我所在公司联系： 北京力高泰科技有限公司 网址：http://www.ecotek.com.cn 电话：010-51665551 电子邮件：info@ecotek.com.cn 地址：北京市西城区西直门南大街2号成铭大厦A座22F "],
["author.html", "关于作者", " 关于作者 祝介东，北京力高泰科技有限公司 工程师，本文内容为我在售后服务时所住的酒店所作（遍布国内大多数省份），本为我打发出差住酒店漫漫长夜的业余爱好，此部分内容并非公司对我的职位所要求的内容，也并非我公司提供的服务内容，因此属于个人作品，仅供参考，我所在公司对此文内容不负任何责任。 "],
["copyright.html", "版权", " 版权 本文旨在对使用我公司产品的用户提供一个数据分析的参考，本人或所在公司并未从中获取任何利益，内容错误疏漏之处，欢迎指正。本人保留一切权利，禁止一切将本文内容用于商业用途的行为，禁止商业公司使用。 "],
["origin-tidyverse.html", "第 1 章 tidyverse 的起源 1.1 tidyverse 的流程", " 第 1 章 tidyverse 的起源 提到 R，他们创始人的名字估计能讲出来的没那么多，但是 Hadley Wickham 绝对是在他发布 ggplot2 成名后，鼎鼎有名的人物。 书归正传，tidyverse 为一些列符合相同设计哲学、语法和数据结构的包的集合，也就是说只要符合这个定义，都可以算作为 tidyverse，不管是不是 tidyverse 已经收录。 本文内容刻意模仿了 R for Data Science，如有兴趣，更建议各位直接看原文。 1.1 tidyverse 的流程 很多时候，一言以蔽之后面的内容听上去很概括，实际上效果远不如一副图片更清晰和直观，例如图 1.1 图 1.1: tidyverse 数据分析的流程 实际上这些处理步骤，大家下意识的就会按照这个进行处理，只不过未将其提炼并系统化而已，多数时候我们导入数据后，这些数据并不能立即使用，通俗的称之为“脏”数据，需要对其进行清洁（例如缺失值等），之后可能需要根据已有数据计算部分数据，处理只好后进行可视化建模，最后整理实验结果，不管发表还是报告等，都是交流的过程。 "],
["prerequisites.html", "第 2 章 准备工作", " 第 2 章 准备工作 需要完成 tidyverse 方式的数据分析，必备的工具有1： R Rstudio tidyverse 其中，tidyverse 安装可分为 CRAN 版和 github 版本，这个无需纠结，二者均可： install.packages(&quot;tidyverse&quot;) 或 devtools::install_github(&quot;tidyverse/tidyverse&quot;) Rstudio 为建议必备，其他编辑器也可↩ "],
["readr.html", "第 3 章 tidyverse 数据格式 3.1 属性的差别 3.2 数据类型的解析 3.3 Julian day 的转换 3.4 常用 package 介绍 3.5 readr 包核心函数 3.6 readxl 3.7 二进制文件 3.8 rio–万能的瑞士军刀", " 第 3 章 tidyverse 数据格式 基本的数据导入，这里我们先通过 tidyverse 中的核心包为readr，引入 tidyverse 对数据导入的核心观点，如果熟悉 read.csv 或其他相似的函数，那么使用 readr 包必然也没有障碍，那么我们先用同样的两种方式，导入相同的 csv 文件，观察其差别： library(tidyverse) ## -- Attaching packages ----------------- tidyverse 1.2.1.9000 -- ## √ ggplot2 3.1.0 √ purrr 0.2.5 ## √ tibble 2.0.1 √ dplyr 0.7.8 ## √ tidyr 0.8.2 √ stringr 1.3.1 ## √ readr 1.3.1 √ forcats 0.3.0 ## -- Conflicts ------------------------- tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() df &lt;- read_csv(&quot;./data/aci_ex.csv&quot;, local = locale(encoding = &quot;latin1&quot;)) ## Parsed with column specification: ## cols( ## .default = col_double(), ## date = col_datetime(format = &quot;&quot;), ## LightAdaptedID = col_character(), ## DarkPulseID = col_character() ## ) ## See spec(...) for full column specifications. df ## # A tibble: 22 x 104 ## obs time elapsed date TIME E A Ci ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1.48e9 7372. 2016-10-02 11:05:33 1.48e9 0.00770 29.5 275. ## 2 2 1.48e9 7374. 2016-10-02 11:05:35 1.48e9 0.00781 26.3 239. ## 3 3 1.48e9 7376. 2016-10-02 11:05:37 1.48e9 0.00790 22.8 205. ## 4 4 1.48e9 7378. 2016-10-02 11:05:39 1.48e9 0.00799 18.6 173. ## 5 5 1.48e9 7380. 2016-10-02 11:05:41 1.48e9 0.00806 14.4 140. ## 6 6 1.48e9 7382. 2016-10-02 11:05:43 1.48e9 0.00822 9.73 110. ## 7 7 1.48e9 7384. 2016-10-02 11:05:45 1.48e9 0.00835 5.01 78.8 ## 8 8 1.48e9 7386. 2016-10-02 11:05:47 1.48e9 0.00839 -0.0205 48.5 ## 9 9 1.48e9 7388. 2016-10-02 11:05:49 1.48e9 0.00860 28.8 286. ## 10 10 1.48e9 7390. 2016-10-02 11:05:51 1.48e9 0.00875 34.9 362. ## # ... with 12 more rows, and 96 more variables: Pci &lt;dbl&gt;, Pca &lt;dbl&gt;, ## # gsw &lt;dbl&gt;, gbw &lt;dbl&gt;, gtw &lt;dbl&gt;, gtc &lt;dbl&gt;, Rabs &lt;dbl&gt;, TleafEB &lt;dbl&gt;, ## # TleafCnd &lt;dbl&gt;, SVPleaf &lt;dbl&gt;, RHcham &lt;dbl&gt;, VPcham &lt;dbl&gt;, ## # SVPcham &lt;dbl&gt;, VPDleaf &lt;dbl&gt;, blfa_1 &lt;dbl&gt;, blfa_2 &lt;dbl&gt;, ## # blfa_3 &lt;dbl&gt;, DarkAdaptedID &lt;dbl&gt;, Fo &lt;dbl&gt;, Fm &lt;dbl&gt;, Fv &lt;dbl&gt;, ## # Fv.Fm &lt;dbl&gt;, Adark &lt;dbl&gt;, LightAdaptedID &lt;chr&gt;, Fs &lt;dbl&gt;, Fm. &lt;dbl&gt;, ## # PhiPS2 &lt;dbl&gt;, PS2.1 &lt;dbl&gt;, Qabs_fs &lt;dbl&gt;, Afs &lt;dbl&gt;, ETR &lt;dbl&gt;, ## # Fv..Fm. &lt;dbl&gt;, PhiCO2 &lt;dbl&gt;, NPQ &lt;dbl&gt;, DarkPulseID &lt;chr&gt;, Fo. &lt;dbl&gt;, ## # Fv. &lt;dbl&gt;, qP &lt;dbl&gt;, qN &lt;dbl&gt;, qP_Fo &lt;dbl&gt;, qN_Fo &lt;dbl&gt;, Qin &lt;dbl&gt;, ## # Qabs &lt;dbl&gt;, alpha &lt;dbl&gt;, convert &lt;dbl&gt;, TIME.1 &lt;dbl&gt;, CO2_s &lt;dbl&gt;, ## # CO2_r &lt;dbl&gt;, H2O_s &lt;dbl&gt;, H2O_r &lt;dbl&gt;, Flow &lt;dbl&gt;, Pa &lt;dbl&gt;, ## # `|¤Pcham` &lt;dbl&gt;, Tair &lt;dbl&gt;, Tleaf &lt;dbl&gt;, Tleaf2 &lt;dbl&gt;, ## # Fan_speed &lt;dbl&gt;, Qamb_in &lt;dbl&gt;, Qamb_out &lt;dbl&gt;, Q &lt;dbl&gt;, f_red &lt;dbl&gt;, ## # f_blue &lt;dbl&gt;, f_farred &lt;dbl&gt;, F &lt;dbl&gt;, Q_modavg &lt;dbl&gt;, F_dc &lt;dbl&gt;, ## # Tled &lt;dbl&gt;, TDigital &lt;dbl&gt;, TPreamp &lt;dbl&gt;, TPwrSpy &lt;dbl&gt;, ## # TDrive &lt;dbl&gt;, F_avg &lt;dbl&gt;, dF.dt &lt;dbl&gt;, dF_dc.dt &lt;dbl&gt;, ## # F_dc_avg &lt;dbl&gt;, period &lt;dbl&gt;, DIAG &lt;dbl&gt;, Flow_s &lt;dbl&gt;, Flow_r &lt;dbl&gt;, ## # Txchg &lt;dbl&gt;, Tirga &lt;dbl&gt;, Tchopper &lt;dbl&gt;, Ts &lt;dbl&gt;, Tr &lt;dbl&gt;, ## # CO2_. &lt;dbl&gt;, Desiccant_. &lt;dbl&gt;, Humidifier_. &lt;dbl&gt;, ## # Heatx_setpoint &lt;dbl&gt;, CO2_r_setpoint &lt;dbl&gt;, H2O_r_setpoint &lt;dbl&gt;, ## # SS_s &lt;dbl&gt;, SS_r &lt;dbl&gt;, MatchH2O &lt;dbl&gt;, MatchCO2 &lt;dbl&gt;, ## # MatchValveR &lt;dbl&gt;, MatchValveS &lt;dbl&gt; df &lt;- read.csv(&quot;./data/aci_ex.csv&quot;) head(df) ## obs time elapsed date TIME E A ## 1 1 1475427934 7372.4 20161002 11:05:33 1475427933 0.007696760 29.47670 ## 2 2 1475427936 7374.4 20161002 11:05:35 1475427935 0.007808186 26.31897 ## 3 3 1475427938 7376.4 20161002 11:05:37 1475427937 0.007901756 22.76927 ## 4 4 1475427940 7378.4 20161002 11:05:39 1475427939 0.007987330 18.61361 ## 5 5 1475427942 7380.4 20161002 11:05:41 1475427941 0.008064806 14.43679 ## 6 6 1475427944 7382.4 20161002 11:05:43 1475427943 0.008215388 9.73141 ## Ci Pci Pca gsw gbw gtw gtc ## 1 274.6465 30.69809 38.03046 0.3432676 2.001378 0.4403924 0.2800793 ## 2 239.3628 30.50294 37.78892 0.3481919 2.007294 0.4405757 0.2801836 ## 3 205.2410 30.36986 37.54531 0.3530725 2.002956 0.4405515 0.2801784 ## 4 172.8188 30.21500 37.29877 0.3561105 2.000471 0.4410542 0.2805097 ## 5 140.4173 30.02464 37.05066 0.3602038 2.003897 0.4407989 0.2803362 ## 6 109.8534 29.89953 36.80124 0.3671059 2.000833 0.4404739 0.2801333 ## Rabs TleafEB TleafCnd SVPleaf RHcham VPcham SVPcham VPDleaf ## 1 165.2454 25.96638 24.9904 3.177858 55.40208 1.979484 3.572942 1.198374 ## 2 165.1947 25.96739 24.9941 3.178559 55.40164 1.979585 3.573152 1.198975 ## 3 165.2454 25.97100 24.9860 3.177025 55.39090 1.979457 3.573614 1.197568 ## 4 165.2454 25.96911 24.9840 3.176646 55.38870 1.979506 3.573845 1.197140 ## 5 165.2437 25.97255 24.9865 3.177119 55.37738 1.979323 3.574244 1.197797 ## 6 165.2454 25.97429 24.9857 3.176968 55.36981 1.979192 3.574496 1.197776 ## blfa_1 blfa_2 blfa_3 DarkAdaptedID Fo Fm Fv Fv.Fm Adark ## 1 -0.03479512 0.03906057 3.019639 0 0 0 0 0 -1 ## 2 -0.03494065 0.03922395 3.029814 0 0 0 0 0 -1 ## 3 -0.03483390 0.03910411 3.022352 0 0 0 0 0 -1 ## 4 -0.03477282 0.03903553 3.018079 0 0 0 0 0 -1 ## 5 -0.03485704 0.03913008 3.023969 0 0 0 0 0 -1 ## 6 -0.03478173 0.03904554 3.018702 0 0 0 0 0 -1 ## LightAdaptedID Fs Fm. PhiPS2 PS2.1 Qabs_fs Afs ETR Fv..Fm. PhiCO2 ## 1 - 0 0 0 0.5 0 0 0 0 0.02699408 ## 2 - 0 0 0 0.5 0 0 0 0 0.02683882 ## 3 - 0 0 0 0.5 0 0 0 0 0.02643125 ## 4 - 0 0 0 0.5 0 0 0 0 0.02611003 ## 5 - 0 0 0 0.5 0 0 0 0 0.02588544 ## 6 - 0 0 0 0.5 0 0 0 0 0.02539339 ## NPQ DarkPulseID Fo. Fv. qP qN qP_Fo qN_Fo Qin Qabs alpha ## 1 0 - 0 0 0 0 0 0 1000.060 843.0848 0.8430005 ## 2 0 - 0 0 0 0 0 0 999.706 843.0932 0.8430005 ## 3 0 - 0 0 0 0 0 0 1000.040 842.8319 0.8430005 ## 4 0 - 0 0 0 0 0 0 999.990 843.0924 0.8429996 ## 5 0 - 0 0 0 0 0 0 999.973 843.0839 0.8429996 ## 6 0 - 0 0 0 0 0 0 999.963 843.0755 0.8429996 ## convert TIME.1 CO2_s CO2_r H2O_s H2O_r Flow Pa ## 1 0.1960010 1475427933 367.719 400.026 23.5181 17.1985 599.683 83.9679 ## 2 0.1960010 1475427935 321.236 350.063 23.5197 17.1997 600.208 83.9672 ## 3 0.1960010 1475427937 275.105 300.048 23.5183 17.2012 599.744 83.9667 ## 4 0.1959991 1475427939 229.601 250.048 23.5189 17.2009 600.127 83.9665 ## 5 0.1959991 1475427941 184.130 200.052 23.5173 17.1997 600.164 83.9654 ## 6 0.1959991 1475427943 139.148 150.023 23.5148 17.1972 599.687 83.9670 ## ΔPcham Tair Tleaf Tleaf2 Fan_speed Qamb_in Qamb_out Q ## 1 0.200645 26.9704 25.0272 999.9 9993.12 0 6.93277 1000.10 ## 2 0.199888 26.9714 24.9913 999.9 10035.00 0 6.93277 1000.11 ## 3 0.199957 26.9736 24.9877 999.9 10004.40 0 6.93277 1000.11 ## 4 0.200108 26.9747 25.0090 999.9 9986.88 0 6.93277 999.79 ## 5 0.199135 26.9766 25.0247 999.9 10011.20 0 6.93277 1000.10 ## 6 0.200911 26.9778 25.0009 999.9 9989.38 0 6.93277 1000.09 ## f_red f_blue f_farred F Q_modavg F_dc Tled TDigital ## 1 0.900015 0.0999851 0 2.8427 0 7893.66 38.812 41.812 ## 2 0.899984 0.1000160 0 2.5274 0 7887.49 38.812 41.812 ## 3 0.899984 0.1000160 0 2.6852 0 7878.68 38.812 41.812 ## 4 0.899984 0.1000160 0 2.6955 0 7869.08 38.812 41.812 ## 5 0.900015 0.0999851 0 2.5337 0 7865.47 38.812 41.812 ## 6 0.900015 0.0999851 0 2.3220 0 7856.35 38.812 41.812 ## TPreamp TPwrSpy TDrive F_avg dF.dt dF_dc.dt F_dc_avg period ## 1 40.437 40.625 39.187 2.617227 -0.5654120 -144.1986 7913.660 15 ## 2 40.437 40.625 39.187 2.616973 -0.6446940 -161.5990 7909.170 15 ## 3 40.437 40.625 39.187 2.585404 -0.5877231 -178.2270 7902.338 15 ## 4 40.437 40.625 39.187 2.602727 -0.4243932 -191.5279 7896.840 15 ## 5 40.437 40.625 39.187 2.579562 -0.1809162 -199.7292 7891.172 15 ## 6 40.437 40.625 39.187 2.550577 0.1461197 -211.9402 7883.021 15 ## DIAG Flow_s Flow_r Txchg Tirga Tchopper Ts Tr CO2_. ## 1 2 506.541 663.349 25.4141 27.5924 30.0001 27.5408 27.5134 29.9284 ## 2 2 501.762 662.342 25.4212 27.5924 30.0001 27.5408 27.5134 29.7805 ## 3 2 514.578 663.419 25.4292 27.5924 30.0000 27.5408 27.5134 29.5901 ## 4 2 498.758 662.436 25.4351 27.5924 30.0000 27.5408 27.5134 29.3941 ## 5 2 522.239 662.835 25.4384 27.5924 30.0000 27.5408 27.5134 29.2541 ## 6 2 504.517 662.881 25.4413 27.5924 30.0000 27.5408 27.5134 29.0845 ## Desiccant_. Humidifier_. Heatx_setpoint CO2_r_setpoint H2O_r_setpoint ## 1 43.693 0 25.4324 460.667 17.2388 ## 2 43.693 0 25.4324 460.667 17.2388 ## 3 43.693 0 25.4390 455.833 17.2388 ## 4 43.693 0 25.4390 450.667 17.2388 ## 5 43.693 0 25.4390 450.667 17.2388 ## 6 43.693 0 25.4491 445.833 17.2388 ## SS_s SS_r MatchH2O MatchCO2 MatchValveR MatchValveS ## 1 100.741 101.259 -0.031 5.465 100 100 ## 2 100.741 101.260 -0.031 5.465 100 100 ## 3 100.742 101.261 -0.031 5.465 100 100 ## 4 100.742 101.261 -0.031 5.465 100 100 ## 5 100.742 101.261 -0.031 5.465 100 100 ## 6 100.743 101.261 -0.031 5.465 100 100 这里先不谈其他，比较一下代码的差别, read_csv 读取同样的我这一个文件，多了一个 local = locale(encoding = \"latin1\") 的设定，看上去复杂了，实际上多数情况是无需的，但我们这个文件内有希腊字母等存在，如果不实用就会提示 input string 1 is invalid in this locale 相关报错，在此不过多解释，相信大家看了下面关于 locale 的一个简单解释就明白了： locale 3.1 属性的差别 我们看一下读取的数据的类有无差别： library(tidyverse) df1 &lt;- read_csv(&quot;./data/aci_ex.csv&quot;, local = locale(encoding = &quot;latin1&quot;)) ## Parsed with column specification: ## cols( ## .default = col_double(), ## date = col_datetime(format = &quot;&quot;), ## LightAdaptedID = col_character(), ## DarkPulseID = col_character() ## ) ## See spec(...) for full column specifications. df2 &lt;- read.csv(&quot;./data/aci_ex.csv&quot;) class(df1) ## [1] &quot;spec_tbl_df&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; class(df2) ## [1] &quot;data.frame&quot; 除了 data.frame 的属性外，readr 除了常规的 data.frame 的类外，还多了几个，它属于 tibble 的属性，我们不多说，看一下 Hadley 大神对 tibble 的解释： Definition 3.1 (tibble definition) Tibbles are a modern reimagining of the data.frame, keeping what time has proven to be effective, and throwing out what is not. tibble 不同于 dataframe 的地方主要在打印和构造子数据集时： Tibbles 只显示前 10 行数据，但会显示所有列，因此大数据时比较方便，此外，除了显示列名外，他还回显示数据类型。 此外，使用 “$” 构造子集时 tibble 要求严格的变量名称。例如： #dataframe df &lt;- head(iris) #tibble tf &lt;- as_tibble(iris) # return results even with wrong name df$Sepal.Leng ## [1] 5.1 4.9 4.7 4.6 5.0 5.4 # error tf$Sepal.Leng ## Warning: Unknown or uninitialised column: &#39;Sepal.Leng&#39;. ## NULL Tibbles 仍然可以使用 [ 和 [[: [ 返回的是另一个 tibble, 而 [[ 返回的是一个向量，不在需要 drop = FALSE! class(iris[ , 1, drop = FALSE]) ## [1] &quot;data.frame&quot; class(as_data_frame(iris)[ , 1]) ## Warning: `as_data_frame()` is deprecated, use `as_tibble()` (but mind the new semantics). ## This warning is displayed once per session. ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; 注意：tibble 和 dataframe 还有一个重要区别是 tibble 不会将字符转换为因子，相当于使用 stringsAsFactors = FALSE 3.2 数据类型的解析 前面已经提到了，tibble 会自动解析数据的类型，但是这个类型是怎么解析的，解析错误怎么办，这就不得不提 parse_* 一系列函数了： str(parse_logical(c(&quot;TRUE&quot;, &quot;FALSE&quot;, &quot;NA&quot;))) ## logi [1:3] TRUE FALSE NA str(parse_integer(c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;))) ## int [1:3] 1 2 3 str(parse_date(c(&quot;2011-01-01&quot;, &quot;1997-10-14&quot;))) ## Date[1:2], format: &quot;2011-01-01&quot; &quot;1997-10-14&quot; 需要注意的是，如果解析失败，在输出时会是 NA，这就是为什么一些他别乱的数据会出现大量 NA 的原因： x &lt;- parse_integer(c(&quot;123&quot;, &quot;456&quot;, &quot;abc&quot;, &quot;123.321&quot;)) ## Warning: 2 parsing failures. ## row col expected actual ## 3 -- an integer abc ## 4 -- no trailing characters .321 x ## [1] 123 456 NA NA ## attr(,&quot;problems&quot;) ## # A tibble: 2 x 4 ## row col expected actual ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 3 NA an integer abc ## 2 4 NA no trailing characters .321 parse_* 有八个函数，他们遵循相同的语法结构，其中： parse_logical 与 parse_integer 类型非常简单，不会出错（数据里面掺杂了其他类型那属于人的错误或机器的错误）。 parse_double 则是严格的解析方式，必须是浮点类型的2，而 parse_number 则相对宽松，我们的问题主要出现在万一你分析的是德国等欧洲国家的数据，反正我第一次看到德国人的发票愣是看了半天才想明白价格。 parse_character 则是非常容易解析的类型，其复杂也在编码上，对于我们来讲，多数情况是不大可能出错的。 parse_factor 功能是创建分类变量，对于我们实验数据时用的非常多的。 parse_datetime, parse_date, parse_time 则是专门解析时间日期的，也是最复杂的，例如常见的英美仪器时间，ISO 时间以及 CR1000 所采用的 julia day 和 LI-6800 所采用的 unix time 或者叫做 POSIX time 或 Epoch Time。 鉴于实际难度和我少打字的原则3，后面我只简单介绍因子类和时间日期类。 3.2.1 因子类型 因子是 R 中用来创建分类数据的，例如 fitacis 用来批量处理不同处理或小区的光合数据，group 参数用的就是 factor 类型，当然，dataframe 格式自动帮我们完成了从 character 到 factor 的转换。当然，需要注意，factor 是有不同水平的，如同我们实验有处理，处理也要分不同的水平，我觉得这个角度理解 factor 非常实在，尤其是对于 农学、林学、生态背景的我们。如果数据里的水平是你后加的，加的时候漏掉了一个水平，那后果也不是很严重，就是分析不能继续，直到你找到错误： fertilizer &lt;- c(&quot;N&quot;, &quot;P&quot;, &quot;K&quot;,&quot;CK&quot;) parse_factor(c(&quot;N&quot;, &quot;P&quot;, &quot;K&quot;, &quot;CK&quot;, &quot;NPK&quot;), levels = fertilizer) ## Warning: 1 parsing failure. ## row col expected actual ## 5 -- value in level set NPK ## [1] N P K CK &lt;NA&gt; ## attr(,&quot;problems&quot;) ## # A tibble: 1 x 4 ## row col expected actual ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 5 NA value in level set NPK ## Levels: N P K CK 如果不幸漏掉了 “NPK” 这个处理，那么这个解析就会报错，无法完成，直到你在 fertilizer 内增加了复合肥4这个处理。 如果更不幸的事情发生了，你排查不到错误，无法将字符转换为因子类型，那么无需着急，我们后面还有其他工具，此时就让他们作为字符类型好了。 3.2.2 时间与日期 parse_datetime 默认解析的方式非常符合中国人的习惯，采用的是 ISO8601, 年月日及时间的方式，如同我最开始数据导入章节 3 举例时，read_csv 十分准确的识别了这个时间。 对于仪器中长用的时间类型，无非是 ISO08601 的标准日期，julian day 日期格式5，POSIX 时间6，以及欧美时间的格式，处理起来各不相同。这里对时间日期的处理采用 lubridate 来处理： library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following object is masked from &#39;package:base&#39;: ## ## date 3.2.2.1 ISO08601 时间及欧美时间的处理 这种时间日期的导入绝大部分能够正常识别，如果不能可以以字符型导入，然后进行解析: ymd_hms(&quot;2019-02-25 21:28:59&quot;) ## [1] &quot;2019-02-25 21:28:59 UTC&quot; mdy_hms(&quot;02-25-2019 21:28:59&quot;) ## [1] &quot;2019-02-25 21:28:59 UTC&quot; 3.3 Julian day 的转换 这个日期尽管看起来奇怪，但是要转换比较容易，base 包即可以。不过我们需要指定起始日期，不然仪器不知道怎么去做，当然，我们既然使用了 lubridate，它也有对应的函数： jday &lt;- c(1, 8, 20, 370) as_date(jday, origin=&quot;2018-01-01&quot;) ## [1] &quot;2018-01-02&quot; &quot;2018-01-09&quot; &quot;2018-01-21&quot; &quot;2019-01-06&quot; 这样就一下子搞定了我们的茎流数据的日期了。 3.3.0.1 POSIX 日期的转换 这个对于广大程序员来讲非常熟悉，但是对于我们生态环境行业来讲，是对人类很不友好的数据格式，但对于转换来讲,其实也非常简单,如果是有具体的时间，则表示以秒为单位计算，我们可以使用 as_datetime： epoch &lt;- c(1, 100, 2.1e+8) as_datetime(epoch) ## [1] &quot;1970-01-01 00:00:01 UTC&quot; &quot;1970-01-01 00:01:40 UTC&quot; ## [3] &quot;1976-08-27 13:20:00 UTC&quot; 3.4 常用 package 介绍 3.5 readr 包核心函数 我们常用的函数，借用 readr cheetsheet 来展示一下其主要用途： 图 3.1: readr 常用函数图解 3.6 readxl 对于读取 excel 格式的文件，一个函数就足够了： read_excel(path, sheet = NULL, range = NULL, col_names = TRUE, col_types = NULL, na = &quot;&quot;, trim_ws = TRUE, skip = 0, n_max = Inf, guess_max = min(1000, n_max), progress = readxl_progress(), .name_repair = &quot;unique&quot;) 自动判断 xls 或者 xlsx 格式来读取，遗憾的是，对于 LI-6400 的 xls 格式，它无能为力，无法读取，对于 LI-6800 的 xlsx 格式，不能正确的识别其公式，因为表头太多了，如果单纯只有测量数据的文件，它是没有问题的。 3.7 二进制文件 此处的二进制文件特指 R 原生的 rds 格式和最新的 feather 格式。他们都是轻量级的数据格式，feather 的优势是能够保存 tibble 数据解析的数据格式。至于读取相应类型的数据，则非常容易，对于我们来讲，其读取的意义在于我们将大量的其他格式数据存储为这两种格式后，进行读取，直接是这两种格式的仪器数据，目前来讲应该还没有。 readRDS(file, refhook = NULL) read_feather(path, columns = NULL) 3.8 rio–万能的瑞士军刀 前面几节介绍读取数据的函数是走马观花，蜻蜓点水的方式，不是故意偷懒，是因为本节内容才是重点，之所以标题将 rio 称之为万能的瑞士军刀，是因为其功能决定的： rio 实际上属于作者对 data.table、haven、readxl 等一系列软件包相关函数的打包，然后将格式的识别自动化，减少了我们的工作量，主要特点为： 使用扩展名来识别文件类型，减少人工输入的工作量，若是格式无法识别，则可以通过指定 format 来导入。 reader 用来处理常见的文本数据，无需指定特定的数据类型。 io 处理自定义数据格式。 ImportExport 集中于处理 excel、SPSS 等二进制文件并提供 shiny 的界面。 SchemaOnRead 则是通过一系列的迭代找到最合适的读取数据的方法。 值得一提的是，rio 尽管使用了 base 函数读取数据，但他从不将字符串当作因子类型处理，遵循 tidyverse 的原则。我们通过举例来完成相关函数的介绍： 3.8.1 安装 rio 安装略微不同于其他软件包，安装好之后，我们最好通过 install_formats() 命令进一步安装其他缺失的软件包，以进一步获得完整的数据格式的支持。 install.packages(&quot;rio&quot;) library(rio) install_formats() 3.8.2 数据的读取 读取数据时，我们可以忘掉原来那一系列函数，只需记得 import 即可： 3.8.2.1 读取 csv 格式数据 library(rio) aci &lt;- import(&quot;./data/aci6800.csv&quot;) 当然，这不足以显示 rio 的优势，因为这种简单格式对 read.csv 也不费力，那我们来点高级的，我这里有一个文件夹，里面放了 4 个 csv 文件： library(plantecophys) paths &lt;- Sys.glob(&quot;./data/multi_csv/*.csv&quot;) all_data &lt;- import_list(paths) fits &lt;- lapply(all_data, fitaci, fitmethod = &quot;bilinear&quot;) fits$aci4$pars ## Estimate Std. Error ## Vcmax 49.3787547 3.4815555 ## Jmax 128.5546403 NA ## Rd 0.3828608 0.4697008 有了 import_list，是不是连 fitacis 也显得多余了？我们无需用 lapply 导入所有数据再合并数据，并加入一列 factor 来区分我们的数据，省时省力，怎么能叫人不喜欢呢？ 3.8.2.2 读取 excel 格式数据 对于 excel 格式的数据读取，我们只需要正确的输入文件名和扩展名即可，不用管它是 xls 还是 xlsx 的格式。下面我有一个 叫做 aci01.xls 的文件，里面有多个 sheet，我们来读取一个叫做 aci2 的 sheet 内的数据： aci2 &lt;- import(&quot;./data/aci01.xls&quot;, sheet = &quot;aci2&quot;) 当然，多数时候我们的数据都是只有一个 sheet 的，或者像我一样不喜欢把所有数据都 分 sheet 放在一个文件的人也很多，所以我们很多时候是不需要这个 sheet = \"aci2 这个参数的，但对于某些仪器，一次导出多个 excel 文件也不时很实用，我们需要的数据恰恰又放在了某个 sheet 中，就很实用了，例如 METERS 的仪器喜欢这么做，拿 SATURO 双水头来讲，如果我们需要原始数据来做处理分析： raw_data &lt;- import(&quot;./data/clay1.xlsx&quot;, sheet = &quot;Raw Data&quot;) knitr::kable(head(raw_data)) Record ID Time (min) Water Level (cm) Pressure (cm) Flux (cm/s) Volume (mL/s) 4 1 4.35 5.506 0.00122 0.2225459 5 2 5.07 4.094 0.00000 0.0000000 6 3 4.97 4.838 0.00323 0.5891995 7 4 4.94 5.605 0.00616 1.1236745 8 5 4.95 5.264 0.00476 0.8682939 9 6 4.94 5.424 0.00555 1.0124015 那如果就是喜欢把所有数据放到一个文件里怎么办，答案我们已经见过： all_aci &lt;- import_list(&quot;./data/aci01.xls&quot;) attributes(all_aci) ## $names ## [1] &quot;aci1&quot; &quot;aci2&quot; &quot;aci3&quot; 如果要进一步处理，参考 3.8.2.1 内容。 3.8.2.3 文本文件的处理 以上两种格式常见，但有时我们会遇到其他文本格式的数据，即虽然数据为文本格式，但都带有其他特别的后缀，例如 CR1000 的数据，如果你曾经用文本编辑器打开过 CR1000 的数据，很容易看到他是用逗号分隔的，那么我们看一下 rio 的表现： crdata &lt;- import(&quot;./data/weather.dat&quot;, format = &quot;,&quot;, skip = 1) knitr::kable(head(crdata)) TIMESTAMP RECORD Batt_volt_Min PTemp_C_Max SR_Wpm2_Avg PAR_umolpm2s_Avg NR_uncorrect_Wpm2_Avg NR_correct_Wpm2_Avg Soil_hf_Wpm2_Avg RG_mm_Tot TCAir_C_Avg RH_Pcent_Avg WS_mps_Avg WS_gust_mps WD_360_Avg TCSoil_C_Avg VWC_Avg Eb_Avg TS RN Min Max Avg Avg Avg Avg Avg Tot Avg Avg Avg Smp Avg Avg Avg Avg 2018-12-14 16:30:00 0 12.84 6.242 28.16 -56.77 -3.978 -3.978 19.54 0 3.148 40.87 NAN 0 0 0 NAN NAN 2018-12-14 17:00:00 1 12.86 4.299 17.75 64.06 -3.7 -3.7 56.13 2 1.623 50.8 0.269 0.13 204.1 0.059 -0.006 1.761 2018-12-14 17:30:00 2 12.88 -0.095 0.713 1.433 -3.044 -3.044 26.31 0 -0.695 71.51 0.195 0.3 254.4 -2.945 -0.017 1.28 2018-12-14 18:00:00 3 12.87 -3.385 -0.006 -0.018 -2.633 -2.633 29.05 0 -1.993 82.6 0.193 0.12 231.9 -3.443 -0.015 1.331 不太好的情况是，我们导 入了表头下 面的一行不需要的 内容，这个我们 先忽略，后面再 处理。 对于 LI-840 等 txt 数据，喜欢用空格分列，使用 rio 的效果非常好，直接自动删除了第一个头文件的日期，读取了我测量的数据： li840 &lt;- import(&quot;./data/li840.txt&quot;) knitr::kable(head(li840)) Date(Y-M-D) Time(H:M:S) CO2(ppm) H2O(ppt) H2O(C) Cell_Temperature(C) Cell_Pressure(kPa) CO2_Absorption H2O_Absorption 2017-06-14 11:07:19 707.61 18.76 16.49 52.19 100.37 0.1328 0.1067 2017-06-14 11:07:20 707.62 18.76 16.49 52.19 100.37 0.1328 0.1067 2017-06-14 11:07:21 707.78 18.77 16.49 52.19 100.35 0.1328 0.1067 2017-06-14 11:07:22 707.87 18.77 16.50 52.19 100.35 0.1328 0.1067 2017-06-14 11:07:23 707.78 18.77 16.50 52.19 100.35 0.1328 0.1067 2017-06-14 11:07:24 707.84 18.77 16.50 52.19 100.35 0.1328 0.1067 R 内没有 float↩ 有时候我会把省掉的补充上，如果后面遇到不得不详细讲的内容时。↩ 农学的童鞋都理解吧，我记得我当时生物统计教材将处理和水平时就用的不同施肥，虽然当时没学好，这么“土的掉渣”的例子我还记得。↩ 一年当中的第几天↩ unix时间，从1970年1月1日开始计算，距离它的秒来几时↩ "],
["rioexport.html", "第 4 章 使用 rio 导出数据 4.1 数据的转换", " 第 4 章 使用 rio 导出数据 与导入数据函数相比，基本上 R 内都有其相对应的导出数据的函数，但为了节省版面，外加这两天培训实在有点累，我们直接进入正题，还是直接进入 “Swiss-Army Knife” 的解决方案： 如果是导入的数据，那么非常容易解决，例如刚刚导入的 CR1000 的数据： exprot(crdata, &quot;./data/crdata.csv&quot;) 如果我想导出多个 dataframe，也非常简单： exprot(all_aci, &quot;./data/all_aci.xlsx&quot;) 也就是第一个参数为多个 dataframe 组成的 list，然后可以将单个 dataframe 导入 excel 不同的 sheet 内。 4.1 数据的转换 rio 数据的转换其实并不奇怪，他是先讲数据导入，然后再导出，目的在于导出，所以我们将它放在了导出数据的内容内。 convert(&quot;./data/aci.csv&quot;, &quot;./data/aci.feather&quot;) 注：转换为 feather 格式，并非耍酷的需要，主要目的有三，一是该格式数据轻量级的，占地方小，二是他是 R 和 python 通用的格式，三是这是二进制格式，文本打开一堆乱码，有一定安全意义，次要目的是耍酷。 "],
["todo.html", "第 5 章 todo 5.1 data transformation 5.2 data visulization 5.3 model r 5.4 public", " 第 5 章 todo 5.1 data transformation 5.2 data visulization 5.3 model r 5.4 public "],
["references.html", "参考文献", " 参考文献 "]
]
